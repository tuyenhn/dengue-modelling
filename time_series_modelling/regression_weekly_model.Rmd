---
output: 
  html_document:
    df_print: paged
    toc: yes
    theme: journal
---

**Knitted at: `r Sys.time()`**

# Libraries

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(tscount)
library(tsibble)
library(feasts)

library(pbapply)
library(parallel)
library(foreach)
library(doParallel)
```

# Settings
```{r}
theme_set(theme_bw())
```


# Data ingestion

```{r}
source("../data_weekly.R", chdir = TRUE)
```


## Incidence data

```{r}
# ggplot(incidence_weekly_df, aes(x = date_admitted, y = n)) +
#   geom_line() +
#   scale_x_yearweek(
#     "Date",
#     breaks = yearweek(paste0(seq(2000, 2023, 1), " W01")), minor_breaks = NULL,
#     labels = as.character(seq(2000, 2023, 1))
#   ) +
#   scale_y_continuous("Case admitted") +
#   ggtitle("Dengue weekly incidence")

# ggsave("weekly_incidence_ts.svg", width = 12, height = 7)
```

### Train test split
```{r}
# incidence_weekly_df %>%
#   filter_index("2000 W01" ~ "2019 W52") %>%
#   ggplot(aes(x = date_admitted, y = n)) +
#   geom_line() +
#   geom_vline(xintercept = as.Date(yearweek("2019 W01")), color = "red") +
#   scale_x_yearweek(
#     "Date",
#     breaks = yearweek(paste0(seq(2000, 2020, 1), " W01")), minor_breaks = NULL,
#     labels = as.character(seq(2000, 2020, 1))
#   ) +
#   scale_y_continuous("Case admitted") +
#   ggtitle("Dengue weekly incidence")

# ggsave("weekly_incidence_split_ts.svg", width = 12, height = 7)
```


```{r}
train_weekly_df <- train_weekly_df %>% bind_rows(val_weekly_df)
train_weekly_df %>% tail()

train_weekly_weather_df <- train_weekly_weather_df %>% bind_rows(val_weekly_weather_df)
train_weekly_weather_df %>% tail()
```

# Correlation analysis

## CCF

"The lag k value returned by ccf(x, y) estimates the correlation between x[t+k] and y[t]."

```{r}
incidence_weekly_weather_df %>%
  CCF(n, t2m, lag_max = 52) %>%
  autoplot()

incidence_weekly_weather_df %>%
  mutate(t2m_lagged = lag(t2m, 27)) %>%
  filter(year(date_admitted) < 2019) %>%
  CCF(n, t2m_lagged, lag_max = 52) %>%
  autoplot()

incidence_weekly_weather_df %>%
  CCF(n, precip, lag_max = 52) %>%
  autoplot()

incidence_weekly_weather_df %>%
  mutate(precip_lagged = lag(precip, 13)) %>%
  filter(year(date_admitted) < 2019) %>%
  CCF(n, precip_lagged, lag_max = 52) %>%
  autoplot()
```

```{r}
# train_weekly_weather_df <- incidence_weekly_weather_df %>%
#   mutate(
#     t2m_lagged = lag(t2m, 27),
#     precip_lagged = lag(precip, 10)
#   ) %>%
#   filter_index("2000 W01" ~ "2018 W52")
#
# test_weekly_weather_df <- incidence_weekly_weather_df %>%
#   mutate(
#     t2m_lagged = lag(t2m, 27),
#     precip_lagged = lag(precip, 10)
#   ) %>%
#   filter(year(date_admitted) == 2019) %>%
#   head(4)
```

# Modelling

## Performance checking framework

```{r}
model_perfs <- tibble(
  model = character(),
  RMSE = numeric(),
  MAE = numeric()
)

chunks_forecast_perf <- function(frcst_df, model_name) {
  res_df <- frcst_df %>%
    group_by(startweek) %>%
    summarise(
      RMSE = sqrt(mean((n - preds)^2)),
      MAE = mean(abs(n - preds))
    )

  avg_rmse <- mean(res_df$RMSE)
  avg_mae <- mean(res_df$MAE)

  print(sprintf("Test mean RMSE: %f", avg_rmse))
  print(sprintf("Test mean MAE: %f", avg_mae))

  model_perfs <<- model_perfs %>%
    bind_rows(tibble(model = model_name, RMSE = avg_rmse, MAE = avg_mae))
}

forecast_plot_default <- function(fit_df, actual_df, plot_title) {
  ggplot(actual_df) +
    geom_line(aes(x = date_admitted, y = n)) +
    forecast_layer(fit_df) +
    scale_x_yearweek(
      "Date",
      breaks = as.Date(actual_df$date_admitted[seq(1, 52, 3)]),
      labels = as.character(actual_df$date_admitted[seq(1, 52, 3)]) %>% str_extract("W\\d+"),
      minor_breaks = NULL
    ) +
    scale_y_continuous("Incidence") +
    ggtitle(plot_title)
}
```

## Model fitting and forecast framework


```{r}
recur_miso <- function(
    train_set, test_set,
    start_indices,
    model = list(), xreg_names = NULL,
    horizon = 4,
    link = c("identity", "log"), distr = c("poisson", "nbinom"),
    cl = NULL) {
  if (!missing(cl)) {
    clusterEvalQ(cl, suppressPackageStartupMessages(library(magrittr)))
    clusterEvalQ(cl, suppressPackageStartupMessages(library(dplyr)))
    clusterEvalQ(cl, library(tscount))
    clusterExport(cl, c("train_set", "test_set"), environment())
  }
  distr <- match.arg(distr)
  link <- match.arg(link)

  pbapply::pblapply(start_indices, \(start_idx) {
    train_df <- train_set %>%
      bind_rows(test_set %>% slice_head(n = start_idx)) %>%
      tail(nrow(train_set))

    if (!is.null(xreg_names)) {
      xreg <- train_df %>%
        as_tibble() %>%
        select(all_of(xreg_names)) %>%
        as.matrix()
      newxreg <- test_set %>%
        tail(52 - start_idx) %>%
        head(horizon) %>%
        as_tibble() %>%
        select(all_of(xreg_names)) %>%
        as.matrix()
    } else {
      xreg <- NULL
      newxreg <- NULL
    }

    fit <- tsglm(train_df$n, model = model, link = link, distr = distr, xreg = xreg)
    pred <- predict(fit, horizon, newobs = NULL, newxreg = newxreg)

    tibble(
      startweek = start_idx,
      actualweek = start_idx + (1:horizon - 1),
      preds = (pred$pred),
      lowers = (pred$interval[, "lower"]),
      uppers = (pred$interval[, "upper"]),
    )
  }, cl = cl) %>% list_c()
}


forecast_layer <- function(frcst_df) {
  # frcst_df <- forecast_df
  frcst_df %<>% group_by(startweek) %>% group_split()

  layers <- lapply(
    frcst_df,
    \(df)
    c(layer(
      data = df,
      geom = "ribbon", stat = "identity", position = "identity",
      mapping = aes(x = date, ymin = lowers, ymax = uppers),
      params = list(alpha = 0.5, fill = "pink")
    ), layer(
      data = df,
      geom = "line", stat = "identity", position = "identity",
      mapping = aes(x = date, y = preds), params = list(color = "red")
    ))
  )
  layers
}
```

```{r}
unregister_dopar <- function() {
  env <- foreach:::.foreachGlobals
  rm(list = ls(name = env), pos = env)
}
```


## Poisson

### 1-week lag
```{r}
poi_covar_forecast_df <- recur_miso(
  train_weekly_weather_df, test_weekly_weather_df,
  seq(1, 49, 3),
  model = list(past_obs = 1),
  link = "log", distr = "poisson"
) %>%
  mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

forecast_plot_default(
  poi_covar_forecast_df, test_weekly_df,
  "4 week forecast - Poisson regression 1-week lag"
)

ggsave("./svgs/forecast_poisson_l1w.svg", height = 7, width = 10)
```

```{r}
train_weekly_weather_df %>% model(TSLM(n ~ date_admitted)) %>% report()

train_weekly_weather_df %>% ggplot(aes(x = date_admitted, y = n)) + geom_point() + geom_smooth(method = "lm")
```



```{r}
poi_1wl_pre_perf_df <- poi_covar_forecast_df %>%
  select(date, preds, startweek) %>%
  left_join(test_weekly_df, by = c("date" = "date_admitted"))

chunks_forecast_perf(
  poi_1wl_pre_perf_df, "Poisson 1-week lag"
)
```


### Auto lagged

```{r}
unregister_dopar()

cl <- makeCluster(9)
clusterEvalQ(cl, library(tidyverse))
clusterEvalQ(cl, library(tscount))
clusterEvalQ(cl, library(tsibble))
registerDoParallel(cl)

auto_lagged_df <- foreach(lag = 1:52) %dopar% {
  forecast_df <- recur_miso(
    train_weekly_weather_df, test_weekly_weather_df,
    seq(1, 49, 3),
    model = list(past_obs = lag),
    link = "log", distr = "poisson"
  ) %>%
    mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())


  res_df <- forecast_df %>%
    select(date, preds, startweek) %>%
    left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
    group_by(startweek) %>%
    summarise(
      RMSE = sqrt(mean((n - preds)^2)),
      MAE = mean(abs(n - preds))
    )

  avg_rmse <- mean(res_df$RMSE)
  avg_mae <- mean(res_df$MAE)

  tibble(model = sprintf("Poisson %d-week lag", lag), RMSE = avg_rmse, MAE = avg_mae, lag = lag)
}

stopCluster(cl)
```

```{r}
lowest_auto_lag <- auto_lagged_df %>%
  list_c() %>%
  filter(RMSE == min(RMSE))

auto_lagged_df %>%
  list_c() %>%
  ggplot(aes(x = lag, y = RMSE)) +
  geom_col() +
  geom_point(data = lowest_auto_lag, shape = 4, color = "red")

model_perfs %<>%
  bind_rows(lowest_auto_lag)

ggsave("./svgs/forecast_poisson_all_lags.svg", width = 10, height = 7)
```


### Weather lagged
 
#### T2m 

```{r}
unregister_dopar()

cl <- makeForkCluster(9)
clusterEvalQ(cl, library(dplyr))
clusterEvalQ(cl, library(tsibble))
clusterEvalQ(cl, library(purrr))
clusterEvalQ(cl, library(tscount))
registerDoParallel(cl)

t2m_lag_df <- foreach(lag = 1:52) %dopar% {
  train_df <- incidence_weekly_weather_df %>%
    mutate(t2m = lag(t2m, lag)) %>%
    filter_index("2000 W01" ~ "2018 W52")

  test_df <- incidence_weekly_weather_df %>%
    mutate(t2m = lag(t2m, lag)) %>%
    filter_index("2019 W01" ~ "2019 W52")

  forecast_df <- recur_miso(
    train_df, test_df,
    seq(1, 49, 3),
    model = list(past_obs = 1), xreg_names = c("t2m"),
    link = "log", distr = "poisson"
  ) %>%
    mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

  res_df <- forecast_df %>%
    select(date, preds, startweek) %>%
    left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
    group_by(startweek) %>%
    summarise(
      RMSE = sqrt(mean((n - preds)^2)),
      MAE = mean(abs(n - preds))
    )

  avg_rmse <- mean(res_df$RMSE)
  avg_mae <- mean(res_df$MAE)

  tibble(model = sprintf("Poisson %d-week t2m lag", lag), RMSE = avg_rmse, MAE = avg_mae, lag = lag)
}

stopCluster(cl)
```

```{r}
lowest_t2m_lag <- t2m_lag_df %>%
  list_c() %>%
  filter(RMSE == min(RMSE))

t2m_lag_df %>%
  list_c() %>%
  ggplot(aes(x = lag, y = RMSE)) +
  geom_col() +
  geom_point(data = lowest_t2m_lag, shape = 4, color = "red")

model_perfs %<>%
  bind_rows(lowest_t2m_lag)

ggsave("./svgs/forecast_poisson_all_t2m_lags.svg", width = 10, height = 7)
```

#### Precipitation

```{r}
unregister_dopar()

cl <- makeForkCluster(9)
clusterEvalQ(cl, library(dplyr))
clusterEvalQ(cl, library(tsibble))
clusterEvalQ(cl, library(purrr))
clusterEvalQ(cl, library(tscount))
registerDoParallel(cl)

precip_lag_df <- foreach(lag = 1:52) %dopar% {
  train_df <- incidence_weekly_weather_df %>%
    mutate(precip = lag(precip, lag)) %>%
    filter_index("2000 W01" ~ "2018 W52")

  test_df <- incidence_weekly_weather_df %>%
    mutate(precip = lag(precip, lag)) %>%
    filter_index("2019 W01" ~ "2019 W52")

  forecast_df <- recur_miso(
    train_df, test_df,
    seq(1, 49, 3),
    model = list(past_obs = 1), xreg_names = c("precip"),
    link = "log", distr = "poisson"
  ) %>%
    mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

  res_df <- forecast_df %>%
    select(date, preds, startweek) %>%
    left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
    group_by(startweek) %>%
    summarise(
      RMSE = sqrt(mean((n - preds)^2)),
      MAE = mean(abs(n - preds))
    )

  avg_rmse <- mean(res_df$RMSE)
  avg_mae <- mean(res_df$MAE)

  tibble(model = sprintf("Poisson %d-week precip lag", lag), RMSE = avg_rmse, MAE = avg_mae, lag = lag)
}

stopCluster(cl)
```

```{r}
lowest_precip_lag <- precip_lag_df %>%
  list_c() %>%
  filter(RMSE == min(RMSE))

precip_lag_df %>%
  list_c() %>%
  ggplot(aes(x = lag, y = RMSE)) +
  geom_col() +
  geom_point(data = lowest_precip_lag, shape = 4, color = "red")

model_perfs %<>%
  bind_rows(lowest_precip_lag)

ggsave("./svgs/forecast_poisson_all_precip_lags.svg", width = 10, height = 7)
```


#### Relative humidity

```{r}
unregister_dopar()

cl <- makeForkCluster(9)
clusterEvalQ(cl, library(dplyr))
clusterEvalQ(cl, library(tsibble))
clusterEvalQ(cl, library(purrr))
clusterEvalQ(cl, library(tscount))
registerDoParallel(cl)

rh_lag_df <- foreach(lag = 1:52) %dopar% {
  train_df <- incidence_weekly_weather_df %>%
    mutate(rh = lag(rh, lag)) %>%
    filter_index("2000 W01" ~ "2018 W52")

  test_df <- incidence_weekly_weather_df %>%
    mutate(rh = lag(rh, lag)) %>%
    filter_index("2019 W01" ~ "2019 W52")


  forecast_df <- recur_miso(
    train_df, test_df,
    seq(1, 49, 3),
    model = list(past_obs = 1), xreg_names = c("rh"),
    link = "log", distr = "poisson"
  ) %>%
    mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

  res_df <- forecast_df %>%
    select(date, preds, startweek) %>%
    left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
    group_by(startweek) %>%
    summarise(
      RMSE = sqrt(mean((n - preds)^2)),
      MAE = mean(abs(n - preds))
    )

  avg_rmse <- mean(res_df$RMSE)
  avg_mae <- mean(res_df$MAE)

  tibble(model = sprintf("Poisson %d-week rh lag", lag), RMSE = avg_rmse, MAE = avg_mae, lag = lag)
}

stopCluster(cl)
```

```{r}
lowest_rh_lag <- rh_lag_df %>%
  list_c() %>%
  filter(RMSE == min(RMSE))

rh_lag_df %>%
  list_c() %>%
  ggplot(aes(x = lag, y = RMSE)) +
  geom_col() +
  geom_point(data = lowest_rh_lag, shape = 4, color = "red")

model_perfs %<>%
  bind_rows(lowest_rh_lag)

ggsave("./svgs/forecast_poisson_all_rh_lags.svg", width = 10, height = 7)
```


### All covariables lagged

```{r}
train_df <- incidence_weekly_weather_df %>%
  mutate(
    t2m = lag(t2m, 14),
    precip = lag(precip, 4),
    rh = lag(rh, 4)
  ) %>%
  filter_index("2000 W01" ~ "2018 W52")

test_df <- incidence_weekly_weather_df %>%
  mutate(
    t2m = lag(t2m, 14),
    precip = lag(precip, 4),
    rh = lag(rh, 4)
  ) %>%
  filter_index("2019 W01" ~ "2019 W52")


poi_covar_forecast_df <- recur_miso(
  train_df, test_df,
  seq(1, 49, 3),
  model = list(past_obs = 1),
  link = "log", distr = "poisson"
) %>%
  mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

forecast_plot_default(
  poi_covar_forecast_df, test_weekly_df,
  "4 week forecast - Poisson regression all covariables lagged"
)
```

```{r}
poi_1wl_pre_perf_df <- poi_covar_forecast_df %>%
  select(date, preds, startweek) %>%
  left_join(test_weekly_df, by = c("date" = "date_admitted"))

chunks_forecast_perf(
  poi_1wl_pre_perf_df, "Poisson all covariables lagged"
)
```

## Negative Binomial

```{r}
nb_covar_forecast_df <- recur_miso(
  train_weekly_weather_df, test_weekly_weather_df,
  seq(1, 49, 3),
  model = list(past_obs = 1),
  link = "log", distr = "nbinom"
) %>%
  mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

forecast_plot_default(
  nb_covar_forecast_df, test_weekly_df,
  "4 week forecast - Negative Binomial regression 1-week lag"
)

ggsave("./svgs/forecast_nb_l1w.svg", height = 7, width = 10)
```

```{r}
nb_1wl_pre_perf_df <- nb_covar_forecast_df %>%
  select(date, preds, startweek) %>%
  left_join(test_weekly_df, by = c("date" = "date_admitted"))

chunks_forecast_perf(
  nb_1wl_pre_perf_df, "NB 1-week lag"
)
```

# Comparison

```{r}
model_perfs
```

```{r}
model_perfs %>% write_csv("glm_models_perf.csv")
```
