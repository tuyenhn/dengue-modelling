---
title: "Dengue weekly incidence modelling"
output: 
  html_document:
    df_print: paged
    toc: yes
    theme: journal
---

**Knitted at: `r Sys.time()`**

# Libraries

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(patchwork)

library(feasts)
library(fable.prophet)
library(fabletools)
library(fable)

library(tsibble)
library(lubridate)

library(parallel)

library(distributional)
```

# Settings
```{r}
theme_set(theme_bw())
set.seed(123)
```


# Data ingestion

```{r}
source("../utils/data_weekly.R", chdir = TRUE)
```


## Incidence data

```{r}
ggplot(incidence_weekly_df, aes(x = date_admitted, y = n)) +
  geom_step() +
  scale_x_yearweek(
    "Date",
    breaks = yearweek(paste0(seq(2000, 2023, 1), " W01")), minor_breaks = NULL,
    labels = as.character(seq(2000, 2023, 1))
  ) +
  scale_y_continuous("Case admitted") +
  ggtitle("Dengue weekly incidence")

ggsave("./svgs/weekly_incidence_ts.svg", width = 12, height = 7)
```

```{r}
train_weekly_df <- train_weekly_df %>% bind_rows(val_weekly_df)
train_weekly_df %>% tail()

train_weekly_weather_df <- train_weekly_weather_df %>% bind_rows(val_weekly_weather_df)
train_weekly_weather_df %>% tail()
```

### Train test split
```{r}
incidence_weekly_df %>%
  filter_index("2000 W01" ~ "2019 W52") %>%
  ggplot(aes(x = date_admitted, y = n)) +
  geom_step() +
  geom_vline(xintercept = as.Date(yearweek("2019 W01")), color = "red") +
  scale_x_yearweek(
    "Date",
    breaks = yearweek(paste0(seq(2000, 2020, 1), " W01")), minor_breaks = NULL,
    labels = as.character(seq(2000, 2020, 1))
  ) +
  scale_y_continuous("Case admitted") +
  ggtitle("Dengue weekly incidence")

ggsave("./svgs/weekly_incidence_split_ts.svg", width = 12, height = 7)
```


# Time series analysis

## STL Decomposition

```{r}
incidence_weekly_df %>%
  model(
    stl_decomp = STL(n ~ season(period = 52, window = "periodic"), robust = TRUE)
  ) %>%
  components() %>%
  autoplot() + xlab("Date")

# ggsave("./svgs/decomp_stl_additive.svg", width = 10, height = 7)
```


## Homoscedasticity

```{r}
skedastic::white(lm(n ~ date_admitted, data = train_weekly_df))
```

```{r}
boxcox_mle <- unclass(MASS::boxcox(lm(n ~ date_admitted, data = train_weekly_df))) %>% as_tibble()

boxcox_white_df <- map(boxcox_mle$x, \(lambda) {
  tibble(
    lambda = lambda,
    transformed_x = list(box_cox(train_weekly_df$n, lambda)),
    white_pvalue = skedastic::white(
      lm(unlist(transformed_x) ~ train_weekly_df$date_admitted)
    )$p.value
  )
}) %>%
  list_c()

boxcox_white_df %>%
  left_join(boxcox_mle, by = c("lambda" = "x")) %>%
  ggplot(aes(x = lambda)) +
  geom_line(aes(y = white_pvalue), color = "red") +
  geom_line(aes(y = (y - min(y)) / 1000000), color = "blue") +
  scale_y_continuous(
    "White test p-value",
    sec.axis = sec_axis(trans = ~ . * 1000000 + min(boxcox_mle$y), name = "log-Likelihood")
  )
```

```{r}
white_lambda <- boxcox_white_df %>%
  filter(lambda > -1) %>%
  filter(white_pvalue == max(white_pvalue)) %>%
  pull(lambda)
boxcox_lambda <- boxcox_mle %>%
  filter(y == max(y)) %>%
  pull(x)
guerrero_lambda <- train_weekly_df %>%
  features(n, features = guerrero) %>%
  pull(lambda_guerrero)

white_lambda
boxcox_lambda
guerrero_lambda
```

## Log transformation

```{r}
# incidence_weekly_df %<>% mutate(n = log(n))
# train_weekly_df %<>% mutate(n = log(n))
# test_weekly_df %<>% mutate(n = log(n))

# ggplot(incidence_weekly_df, aes(x = date_admitted, y = n)) +
#   geom_line() +
#   xlab("Date") +
#   ylab("Log-transformed incidence")
#
# ggsave("./svgs/weekly_incidence_log_trans.svg", width = 10, height = 7)
```


```{r}
# train_weekly_weather_df %<>% mutate(n = log(n))
# test_weekly_weather_df %<>% mutate(n = log(n))
```

# Modelling

## Framework

### Performance checking 

```{r}
model_perfs <- tibble(
  model = character(),
  RMSE = numeric(),
  CRPS = numeric(),
)

source("../utils/performance_checking_framework.R", chdir = TRUE)
```

### Forecast framework
```{r}
source("../utils/forecast_plotting.R", chdir = TRUE)
source("../utils/chunks_forecasting.R", chdir = TRUE)

forecast_plot_default <- function(fit_df, actual_df, plot_title) {
  ggplot(actual_df) +
    geom_line(aes(x = date_admitted, y = n)) +
    forecast_layer(fit_df) +
    scale_x_yearweek(
      "Week",
      breaks = test_weekly_df$date_admitted[seq(0, 52, 3) + 1],
      labels = as.character(test_weekly_df$date_admitted[seq(0, 52, 3) + 1]) %>% str_extract("W\\d+"),
      minor_breaks = NULL
    ) +
    scale_y_continuous("Incidence") +
    ggtitle(plot_title)
}
```

## Time series differencing

Quickly check if any differencing needed, both seasonal and non-seasonal

```{r}
train_weekly_df %>% features(n, unitroot_ndiffs)
train_weekly_df %>% features(n, unitroot_nsdiffs)
```

```{r}
train_weekly_df %>%
  gg_tsdisplay(
    difference(n),
    plot_type = "partial",
    lag = 52
  )

train_weekly_df %>%
  gg_tsdisplay(
    difference(n, 52),
    plot_type = "partial",
    lag = 208
  )
```
```{r}
local_get_coef <- \(fit) fit %>%
  coef() %>%
  select(c(term, estimate)) %>%
  deframe() %>%
  as.list()
```


## AR

### Base model
```{r}
ar_fit <- train_weekly_df %>% model(AR(log(n)))
report(ar_fit)

cat("\n\n")

coefs <- local_get_coef(ar_fit) %>% tail(-1)
coefs
```

### Chunks
```{r}
ar_chunks_fit <- forecast_chunks(
  train_weekly_df, test_weekly_df, seq(0, 49, 3),
  AR, log(n) ~ order(p = 10, fixed = coefs)
)

p1 <- forecast_plot_default(
  ar_chunks_fit,
  test_weekly_df,
  "4 week forecast - AR(10)"
)
p1

ggsave("./svgs/forecast_ar10.svg", width = 10, height = 7)
```

```{r}
pre_perf_df <- ar_chunks_fit %>%
  select(date_admitted, n, .mean, startweek) %>%
  rename(dist = n) %>%
  left_join(test_weekly_df, by = "date_admitted")

chunks_forecast_res_df <- chunks_forecast_perf(
  pre_perf_df, "AR(10)",
  scoringRules::crps_norm, mean(dist), sqrt(variance(dist))
)

p2 <- metrics_plot(chunks_forecast_res_df, pre_perf_df$date_admitted)

p1 / p2
```

## MA

### Base model

```{r}
lapply(0:7, \(q){
  fit <- train_weekly_df %>% model(
    ARIMA(log(n) ~ pdq(0, 0, q) + PDQ(0, 0, 0))
  )
  tibble(q = q, aicc = (glance(fit))$AICc)
}) %>% list_c()
```


```{r}
ma_fit <- train_weekly_df %>% model(ARIMA(log(n) ~ pdq(0, 0, 6) + PDQ(0, 0, 0)))
report(ma_fit)

cat("\n\n")

coefs <- local_get_coef(ma_fit) %>% head(-1)
coefs
```

### Chunks

```{r}
ma_chunks_fit <- forecast_chunks(
  train_weekly_df, test_weekly_df, seq(0, 49, 3),
  ARIMA, n ~ pdq(0, 0, 6, fixed = coefs) + PDQ(0, 0, 0)
)

p1 <- forecast_plot_default(
  ma_chunks_fit,
  test_weekly_df,
  "4 week forecast - MA(6)"
)
p1

ggsave("./svgs/forecast_ma6.svg", width = 10, height = 7)
```


```{r}
pre_perf_df <- ma_chunks_fit %>%
  select(date_admitted, n, .mean, startweek) %>%
  rename(dist = n) %>%
  left_join(test_weekly_df, by = "date_admitted")

chunks_forecast_res_df <- chunks_forecast_perf(
  pre_perf_df, "MA(6)",
  scoringRules::crps_norm, mean(dist), sqrt(variance(dist))
)

p2 <- metrics_plot(chunks_forecast_res_df, pre_perf_df$date_admitted)

p1 / p2
```


## ARIMA
### Base model
```{r}
arima_fit <- train_weekly_df %>% model(ARIMA(log(n) ~ PDQ(0, 0, 0), stepwise = FALSE))
report(arima_fit)

coefs <- local_get_coef(arima_fit)
coefs
```

### Chunks
```{r}
arima_chunks_fit <- forecast_chunks(
  train_weekly_df, test_weekly_df, seq(0, 49, 3),
  ARIMA, log(n) ~ pdq(3, 1, 3, fixed = coefs) + PDQ(0, 0, 0)
)

p1 <- forecast_plot_default(
  arima_chunks_fit,
  test_weekly_df,
  "4 week forecast - ARIMA(3,1,3)"
)
p1

ggsave("./svgs/forecast_arima.svg", width = 10, height = 7)
```


```{r}
pre_perf_df <- arima_chunks_fit %>%
  select(date_admitted, n, .mean, startweek) %>%
  rename(dist = n) %>%
  left_join(test_weekly_df, by = "date_admitted")

chunks_forecast_res_df <- chunks_forecast_perf(
  pre_perf_df, "ARIMA(3,1,3)",
  scoringRules::crps_norm, mean(dist), sqrt(variance(dist))
)

p2 <- metrics_plot(chunks_forecast_res_df, pre_perf_df$date_admitted)

p1 / p2
```

## SARIMA
### Base model
```{r}
#    user  system elapsed
# 333.511  58.153 386.774
system.time({
  sarima_fit <- train_weekly_df %>% model(ARIMA(log(n)))
})
report(sarima_fit)

sarima_coefs <- local_get_coef(sarima_fit)
sarima_coefs
```



### Chunks
```{r}
sarima_chunks_fit <- forecast_chunks(
  train_weekly_df, test_weekly_df, seq(0, 49, 3),
  ARIMA, log(n) ~ pdq(0, 1, 1, fixed = sarima_coefs[1]) + PDQ(2, 1, 0, fixed = sarima_coefs[-1])
)

p1 <- forecast_plot_default(
  sarima_chunks_fit,
  test_weekly_df,
  "4 week forecast - SARIMA"
)
p1
ggsave("./svgs/forecast_sarima.svg", width = 10, height = 7)
```


```{r}
pre_perf_df <- sarima_chunks_fit %>%
  select(date_admitted, n, .mean, startweek) %>%
  rename(dist = n) %>%
  left_join(test_weekly_df, by = "date_admitted")

chunks_forecast_res_df <- chunks_forecast_perf(
  pre_perf_df, "SARIMA(1,0,1)(1,1,0)",
  scoringRules::crps_norm, mean(dist), sqrt(variance(dist))
)

p2 <- metrics_plot(chunks_forecast_res_df, pre_perf_df$date_admitted)

p1 / p2
```

## Prophet weekly

### Base model
```{r}
cl <- makeCluster(6)
invisible(clusterEvalQ(cl, library(fable.prophet)))
invisible(clusterEvalQ(cl, library(tidyverse)))
clusterExport(cl, c("train_weekly_weather_df", "test_weekly_weather_df"))

fn1 <- function() {
  forecast_chunks(
    train_weekly_weather_df, test_weekly_weather_df, seq(0, 49, 3),
    prophet, n ~ season(period = 52, order = 10, type = "additive")
  )
}
fn2 <- function() {
  forecast_chunks(
    train_weekly_weather_df, test_weekly_weather_df, seq(0, 49, 3),
    prophet, n ~ season(period = 52, order = 10, type = "multiplicative")
  )
}

expr_v <- c(substitute(fn1()), substitute(fn2()))
# fits <- mclapply(expr_v, eval, mc.cores = 2)
clusterExport(cl, lsf.str())
fits <- parLapply(cl, expr_v, eval)
stopCluster(cl)

setNames(fits, c("prophet_addi_fit", "prophet_multi_fit")) %>%
  list2env(envir = .GlobalEnv)

prophet_addi_fit
prophet_multi_fit
```


```{r}
p1_prophet_a <- forecast_plot_default(
  prophet_addi_fit,
  test_weekly_df,
  "4 week forecast - Prophet additive"
)
p1_prophet_a

ggsave("./svgs/forecast_prophet_addi.svg", width = 10, height = 7)

p1_prophet_m <- forecast_plot_default(
  prophet_multi_fit,
  test_weekly_df,
  "4 week forecast - Prophet multiplicative"
)
p1_prophet_m

ggsave("./svgs/forecast_prophet_multi.svg", width = 10, height = 7)
```

```{r}
addi_pre_perf_df <- prophet_addi_fit %>%
  select(date_admitted, n, .mean, startweek) %>%
  rename(dist = n) %>%
  left_join(test_weekly_df, by = "date_admitted")

chunks_addi_forecast_res_df <- chunks_forecast_perf(
  addi_pre_perf_df, "Prophet additive",
  scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
)
p2_addi <- metrics_plot(chunks_addi_forecast_res_df, addi_pre_perf_df$date_admitted)

p1_prophet_a / p2_addi

multi_pre_perf_df <- prophet_multi_fit %>%
  select(date_admitted, n, .mean, startweek) %>%
  rename(dist = n) %>%
  left_join(test_weekly_df, by = "date_admitted")

chunks_multi_forecast_res_df <- chunks_forecast_perf(
  multi_pre_perf_df, "Prophet multiplicative",
  scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
)
p2_multi <- metrics_plot(chunks_multi_forecast_res_df, multi_pre_perf_df$date_admitted)

p1_prophet_m / p2_multi
```

### With holidays

```{r fig.height=15, fig.width=15, warning=FALSE}
pub_holidays <- map(2000:2022, \(year){
  c(
    sprintf("%d-01-01", year),
    sprintf("%d-12-29", subtract(year, 1)) %>% lunR::lunar_to_gregorian(),
    sprintf("%d-03-10", year) %>% lunR::lunar_to_gregorian(),
    sprintf("%d-04-30", year),
    sprintf("%d-05-01", year),
    sprintf("%d-09-02", year)
  )
}) %>%
  list_c() %>%
  as.Date()

vn_pub_holidays <- tsibble(
  date = pub_holidays,
  holiday = rep(
    c("New Year", "Tet", "Hung King", "Reunification", "Labor Day", "Independence Day"),
    23
  ),
  lower_window = rep(c(0, 0, 0, 0, 0, 0), 23),
  upper_window = rep(c(1, 7, 1, 1, 1, 2), 23),
  index = date
)

vn_pub_holidays_train <- vn_pub_holidays %>% filter(year(date) < 2019)

incidence_weekly_df %>%
  mutate(year = year(date_admitted), n = n) %>%
  autoplot() +
  geom_vline(data = vn_pub_holidays, aes(xintercept = date), color = "red", alpha = 0.3) +
  facet_wrap(~year, scales = "free_x")

ggsave("./svgs/weekly_incidence_w_holiday.svg", width = 10, height = 7)
```

```{r}
prophet_holiday_fit <- forecast_chunks(
  train_weekly_weather_df, test_weekly_weather_df, seq(0, 49, 3),
  prophet, n ~ season(period = 52, order = 10, type = "multiplicative") + holiday(vn_pub_holidays_train)
)
prophet_holiday_fit
```

```{r}
p1_hol <- forecast_plot_default(
  prophet_holiday_fit, test_weekly_df,
  "4 week forecast - Prophet multiplicative + holidays"
)
p1_hol
ggsave("./svgs/forecast_prophet_holiday.svg", width = 10, height = 7)
```


```{r}
prophet_holiday_pre_perf_df <- prophet_holiday_fit %>%
  select(date_admitted, n, .mean, startweek) %>%
  rename(dist = n) %>%
  left_join(test_weekly_df, by = "date_admitted")

chunks_forecast_res_df <- chunks_forecast_perf(
  prophet_holiday_pre_perf_df, "Prophet multiplicative + holidays",
  scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
)

p2_hol <- metrics_plot(chunks_forecast_res_df, pre_perf_df$date_admitted)

p1_hol / p2_hol
```

# Comparison
```{r}
model_perfs
```

```{r}
model_perfs %>% write_csv("parametric_models_perf.csv")
```
