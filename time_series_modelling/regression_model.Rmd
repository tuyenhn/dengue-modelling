---
output: 
  html_document:
    df_print: paged
    toc: yes
    theme: journal
---

**Knitted at: `r Sys.time()`**

# Libraries

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(tscount)
library(tsibble)
library(feasts)
library(patchwork)

library(pbapply)
library(parallel)
library(foreach)
library(doParallel)

library(distributional)
```

# Settings
```{r}
theme_set(theme_bw())
set.seed(123)
```


# Data ingestion

```{r}
source("../data_weekly.R", chdir = TRUE)
```


## Incidence data

```{r}
# ggplot(incidence_weekly_df, aes(x = date_admitted, y = n)) +
#   geom_line() +
#   scale_x_yearweek(
#     "Date",
#     breaks = yearweek(paste0(seq(2000, 2023, 1), " W01")), minor_breaks = NULL,
#     labels = as.character(seq(2000, 2023, 1))
#   ) +
#   scale_y_continuous("Case admitted") +
#   ggtitle("Dengue weekly incidence")

# ggsave("weekly_incidence_ts.svg", width = 12, height = 7)
```

### Train test split
```{r}
# incidence_weekly_df %>%
#   filter_index("2000 W01" ~ "2019 W52") %>%
#   ggplot(aes(x = date_admitted, y = n)) +
#   geom_line() +
#   geom_vline(xintercept = as.Date(yearweek("2019 W01")), color = "red") +
#   scale_x_yearweek(
#     "Date",
#     breaks = yearweek(paste0(seq(2000, 2020, 1), " W01")), minor_breaks = NULL,
#     labels = as.character(seq(2000, 2020, 1))
#   ) +
#   scale_y_continuous("Case admitted") +
#   ggtitle("Dengue weekly incidence")

# ggsave("weekly_incidence_split_ts.svg", width = 12, height = 7)
```


```{r}
train_weekly_df <- train_weekly_df %>% bind_rows(val_weekly_df)
train_weekly_df %>% tail()

train_weekly_weather_df <- train_weekly_weather_df %>% bind_rows(val_weekly_weather_df)
train_weekly_weather_df %>% tail()
```

# Correlation analysis

## CCF

"The lag k value returned by ccf(x, y) estimates the correlation between x[t+k] and y[t]."

```{r}
incidence_weekly_weather_df %>%
  CCF(n, t2m, lag_max = 52) %>%
  autoplot()

incidence_weekly_weather_df %>%
  mutate(t2m_lagged = lag(t2m, 27)) %>%
  filter(year(date_admitted) < 2019) %>%
  CCF(n, t2m_lagged, lag_max = 52) %>%
  autoplot()

incidence_weekly_weather_df %>%
  CCF(n, precip, lag_max = 52) %>%
  autoplot()

incidence_weekly_weather_df %>%
  mutate(precip_lagged = lag(precip, 13)) %>%
  filter(year(date_admitted) < 2019) %>%
  CCF(n, precip_lagged, lag_max = 52) %>%
  autoplot()
```

```{r}
# train_weekly_weather_df <- incidence_weekly_weather_df %>%
#   mutate(
#     t2m_lagged = lag(t2m, 27),
#     precip_lagged = lag(precip, 10)
#   ) %>%
#   filter_index("2000 W01" ~ "2018 W52")
#
# test_weekly_weather_df <- incidence_weekly_weather_df %>%
#   mutate(
#     t2m_lagged = lag(t2m, 27),
#     precip_lagged = lag(precip, 10)
#   ) %>%
#   filter(year(date_admitted) == 2019) %>%
#   head(4)
```

# Modelling

## Performance checking framework

```{r}
model_perfs <- tibble(
  model = character(),
  RMSE = numeric(),
  CRPS = numeric(),
)

source("../utils/performance_checking_framework.R", chdir = TRUE)
```


```{r}
source("../utils/forecast_plotting.R", chdir = TRUE)
source("../utils/chunks_forecasting.R", chdir = TRUE)

forecast_plot_default <- function(fit_df, actual_df, plot_title) {
  fit_df %<>% rename(date_admitted = date, .mean = preds, n = dist)
  ggplot(actual_df) +
    geom_line(aes(x = date_admitted, y = n)) +
    forecast_layer(fit_df) +
    scale_x_yearweek(
      "Week",
      breaks = actual_df$date_admitted[seq(0, 52, 3) + 1],
      labels = as.character(actual_df$date_admitted[seq(0, 52, 3) + 1]) %>% str_extract("W\\d+"),
      minor_breaks = NULL
    ) +
    scale_y_continuous("Incidence") +
    ggtitle(plot_title)
}
```

## Model fitting and forecast framework


```{r}
source("../utils/regression_recur_miso.R", chdir = TRUE)
```

```{r}
unregister_dopar <- function() {
  env <- foreach:::.foreachGlobals
  rm(list = ls(name = env), pos = env)
}
```


## Poisson

### 1-week lag
```{r}
poi_covar_forecast_df <- recur_miso(
  train_weekly_weather_df, test_weekly_weather_df,
  seq(1, 49, 3),
  model = list(past_obs = 1),
  link = "log", distr = "poisson"
) %>%
  mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

p1 <- forecast_plot_default(
  poi_covar_forecast_df, test_weekly_df,
  "4 week forecast - Poisson regression 1-week lag"
)
p1

ggsave("./svgs/forecast_poisson_l1w.svg", height = 7, width = 10)
```



```{r}
poi_1wl_pre_perf_df <- poi_covar_forecast_df %>%
  select(date, dist, preds, startweek) %>%
  left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
  rename(.mean = preds)

chunks_forecast_res_df <- chunks_forecast_perf(
  poi_1wl_pre_perf_df, "Poisson 1-week lag",
  scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
)

p2 <- metrics_plot(chunks_forecast_res_df, poi_1wl_pre_perf_df$date)
p1 / p2
```


### Auto lagged

```{r}
unregister_dopar()

cl <- makeCluster(9)
clusterEvalQ(cl, library(tidyverse))
clusterEvalQ(cl, library(magrittr))
clusterEvalQ(cl, library(tscount))
clusterEvalQ(cl, library(tsibble))
clusterEvalQ(cl, library(distributional))
registerDoParallel(cl)

auto_lagged_df <- foreach(lag = 1:20) %dopar% {
  forecast_df <- recur_miso(
    train_weekly_weather_df, test_weekly_weather_df,
    seq(1, 49, 3),
    model = list(past_obs = lag),
    link = "log", distr = "poisson"
  ) %>%
    mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

  pre_perf_df <- forecast_df %>%
    select(date, dist, preds, startweek) %>%
    left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
    rename(.mean = preds)

  chunks_forecast_res_df <- chunks_forecast_perf(
    pre_perf_df, sprintf("Poisson %d-week lag", lag),
    scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
  )

  tibble(
    model = sprintf("Poisson %d-week lag", lag),
    RMSE = mean(chunks_forecast_res_df$RMSE),
    CRPS = mean(chunks_forecast_res_df$CRPS),
    lag = lag
  )
}

stopCluster(cl)
```

```{r}
lowest_auto_lag <- auto_lagged_df %>%
  list_c() %>%
  filter(CRPS == min(CRPS))

auto_lagged_df %>%
  list_c() %>%
  ggplot(aes(x = lag, y = CRPS)) +
  geom_col() +
  # geom_col(aes(x = lag, y = -RMSE)) +
  geom_point(data = lowest_auto_lag, shape = 4, color = "red", size = 2, stroke = 1.5)

model_perfs %<>%
  bind_rows(lowest_auto_lag)

ggsave("./svgs/forecast_poisson_all_lags.svg", width = 10, height = 7)
```


### Weather lagged
 
#### T2m 

```{r}
unregister_dopar()

cl <- makeCluster(9)
clusterEvalQ(cl, library(dplyr))
clusterEvalQ(cl, library(tsibble))
clusterEvalQ(cl, library(purrr))
clusterEvalQ(cl, library(tscount))
clusterEvalQ(cl, library(distributional))
clusterExport(cl, c("%<>%"))
registerDoParallel(cl)

t2m_lag_df <- foreach(lag = 1:20) %dopar% {
  train_df <- incidence_weekly_weather_df %>%
    mutate(t2m = lag(t2m, lag)) %>%
    filter_index("2000 W01" ~ "2018 W52")

  test_df <- incidence_weekly_weather_df %>%
    mutate(t2m = lag(t2m, lag)) %>%
    filter_index("2019 W01" ~ "2019 W52")

  forecast_df <- recur_miso(
    train_df, test_df,
    seq(1, 49, 3),
    model = list(past_obs = 1), xreg_names = c("t2m"),
    link = "log", distr = "poisson"
  ) %>%
    mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

  pre_perf_df <- forecast_df %>%
    select(date, dist, preds, startweek) %>%
    left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
    rename(.mean = preds)

  chunks_forecast_res_df <- chunks_forecast_perf(
    pre_perf_df, sprintf("Poisson %d-week t2m lag", lag),
    scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
  )

  tibble(
    model = sprintf("Poisson %d-week t2m lag", lag),
    RMSE = mean(chunks_forecast_res_df$RMSE),
    CRPS = mean(chunks_forecast_res_df$CRPS),
    lag = lag
  )
}

stopCluster(cl)
```

```{r}
lowest_t2m_lag <- t2m_lag_df %>%
  list_c() %>%
  filter(CRPS == min(CRPS))

t2m_lag_df %>%
  list_c() %>%
  ggplot(aes(x = lag, y = CRPS)) +
  geom_col() +
  geom_point(data = lowest_t2m_lag, shape = 4, color = "red", size = 2, stroke = 1.5)

model_perfs %<>%
  bind_rows(lowest_t2m_lag)

ggsave("./svgs/forecast_poisson_all_t2m_lags.svg", width = 10, height = 7)
```

#### Precipitation

```{r}
unregister_dopar()

cl <- makeCluster(9)
clusterEvalQ(cl, library(dplyr))
clusterEvalQ(cl, library(tsibble))
clusterEvalQ(cl, library(purrr))
clusterEvalQ(cl, library(tscount))
clusterEvalQ(cl, library(distributional))
clusterExport(cl, c("%<>%"))
registerDoParallel(cl)

precip_lag_df <- foreach(lag = 1:20) %dopar% {
  train_df <- incidence_weekly_weather_df %>%
    mutate(precip = lag(precip, lag)) %>%
    filter_index("2000 W01" ~ "2018 W52")

  test_df <- incidence_weekly_weather_df %>%
    mutate(precip = lag(precip, lag)) %>%
    filter_index("2019 W01" ~ "2019 W52")

  forecast_df <- recur_miso(
    train_df, test_df,
    seq(1, 49, 3),
    model = list(past_obs = 1), xreg_names = c("precip"),
    link = "log", distr = "poisson"
  ) %>%
    mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

  pre_perf_df <- forecast_df %>%
    select(date, dist, preds, startweek) %>%
    left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
    rename(.mean = preds)

  chunks_forecast_res_df <- chunks_forecast_perf(
    pre_perf_df, sprintf("Poisson %d-week precip lag", lag),
    scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
  )

  tibble(
    model = sprintf("Poisson %d-week precip lag", lag),
    RMSE = mean(chunks_forecast_res_df$RMSE),
    CRPS = mean(chunks_forecast_res_df$CRPS),
    lag = lag
  )
}

stopCluster(cl)
```

```{r}
lowest_precip_lag <- precip_lag_df %>%
  list_c() %>%
  filter(CRPS == min(CRPS))

precip_lag_df %>%
  list_c() %>%
  ggplot(aes(x = lag, y = CRPS)) +
  geom_col() +
  geom_point(data = lowest_precip_lag, shape = 4, color = "red", size = 2, stroke = 1.5)

model_perfs %<>%
  bind_rows(lowest_precip_lag)

ggsave("./svgs/forecast_poisson_all_precip_lags.svg", width = 10, height = 7)
```


#### Relative humidity

```{r}
unregister_dopar()

cl <- makeCluster(9)
clusterEvalQ(cl, library(dplyr))
clusterEvalQ(cl, library(tsibble))
clusterEvalQ(cl, library(purrr))
clusterEvalQ(cl, library(tscount))
clusterEvalQ(cl, library(distributional))
clusterExport(cl, c("%<>%"))
registerDoParallel(cl)

rh_lag_df <- foreach(lag = 1:20) %dopar% {
  train_df <- incidence_weekly_weather_df %>%
    mutate(rh = lag(rh, lag)) %>%
    filter_index("2000 W01" ~ "2018 W52")

  test_df <- incidence_weekly_weather_df %>%
    mutate(rh = lag(rh, lag)) %>%
    filter_index("2019 W01" ~ "2019 W52")


  forecast_df <- recur_miso(
    train_df, test_df,
    seq(1, 49, 3),
    model = list(past_obs = 1), xreg_names = c("rh"),
    link = "log", distr = "poisson"
  ) %>%
    mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

  pre_perf_df <- forecast_df %>%
    select(date, dist, preds, startweek) %>%
    left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
    rename(.mean = preds)

  chunks_forecast_res_df <- chunks_forecast_perf(
    pre_perf_df, sprintf("Poisson %d-week rh lag", lag),
    scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
  )

  tibble(
    model = sprintf("Poisson %d-week rh lag", lag),
    RMSE = mean(chunks_forecast_res_df$RMSE),
    CRPS = mean(chunks_forecast_res_df$CRPS),
    lag = lag
  )
}

stopCluster(cl)
```

```{r}
lowest_rh_lag <- rh_lag_df %>%
  list_c() %>%
  filter(CRPS == min(CRPS))

rh_lag_df %>%
  list_c() %>%
  ggplot(aes(x = lag, y = CRPS)) +
  geom_col() +
  geom_point(data = lowest_rh_lag, shape = 4, color = "red", size = 2, stroke = 1.5)

model_perfs %<>%
  bind_rows(lowest_rh_lag)

ggsave("./svgs/forecast_poisson_all_rh_lags.svg", width = 10, height = 7)
```


### All covariables lagged

```{r}
covar_lagged_df <- incidence_weekly_weather_df %>%
  mutate(
    t2m = lag(t2m, 14),
    precip = lag(precip, 3),
    rh = lag(rh, 3)
  )

train_df <- covar_lagged_df %>%
  filter_index("2000 W01" ~ "2018 W52")

test_df <- covar_lagged_df %>%
  filter_index("2019 W01" ~ "2019 W52")


poi_covar_forecast_df <- recur_miso(
  train_df, test_df,
  seq(1, 49, 3),
  model = list(past_obs = 1), xreg_names = c("t2m", "precip", "rh"),
  link = "log", distr = "poisson"
) %>%
  mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

p1 <- forecast_plot_default(
  poi_covar_forecast_df, test_weekly_df,
  "4 week forecast - Poisson regression all covariables lagged"
)
p1

ggsave("./svgs/forecast_poisson_all_covar_lags.svg", width = 10, height = 7)
```

```{r}
poi_covars_pre_perf_df <- poi_covar_forecast_df %>%
  select(date, dist, preds, startweek) %>%
  left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
  rename(.mean = preds)

chunks_forecast_res_df <- chunks_forecast_perf(
  poi_covars_pre_perf_df, "Poisson all covariables lagged",
  scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
)

p2 <- metrics_plot(chunks_forecast_res_df, poi_covars_pre_perf_df$date)
p1 / p2
```

## Negative Binomial

```{r}
nb_covar_forecast_df <- recur_miso(
  train_weekly_weather_df, test_weekly_weather_df,
  seq(1, 49, 3),
  model = list(past_obs = 1),
  link = "log", distr = "nbinom"
) %>%
  mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

forecast_plot_default(
  nb_covar_forecast_df, test_weekly_df,
  "4 week forecast - Negative Binomial regression 1-week lag"
)

ggsave("./svgs/forecast_nb_l1w.svg", height = 7, width = 10)
```

```{r}
nb_1wl_pre_perf_df <- nb_covar_forecast_df %>%
  select(date, preds, startweek) %>%
  left_join(test_weekly_df, by = c("date" = "date_admitted"))

chunks_forecast_perf(
  nb_1wl_pre_perf_df, "NB 1-week lag"
)
```

# Comparison

```{r}
model_perfs
```

```{r}
model_perfs %>% write_csv("glm_models_perf.csv")
```
