---
output: 
  html_document:
    df_print: paged
    toc: yes
    theme: journal
---

**Knitted at: `r Sys.time()`**

# Libraries

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(tscount)
library(tsibble)
library(feasts)
library(patchwork)

library(pbapply)
library(parallel)
library(foreach)
library(doParallel)

library(distributional)
```

# Settings
```{r}
theme_set(theme_bw())
set.seed(123)
```


# Data ingestion

```{r}
source("../utils/data_weekly.R", chdir = TRUE)
```


## Incidence data

```{r}
# ggplot(incidence_weekly_df, aes(x = date_admitted, y = n)) +
#   geom_line() +
#   scale_x_yearweek(
#     "Date",
#     breaks = yearweek(paste0(seq(2000, 2023, 1), " W01")), minor_breaks = NULL,
#     labels = as.character(seq(2000, 2023, 1))
#   ) +
#   scale_y_continuous("Case admitted") +
#   ggtitle("Dengue weekly incidence")

# ggsave("weekly_incidence_ts.svg", width = 12, height = 7)
```

### Train test split
```{r}
# incidence_weekly_df %>%
#   filter_index("2000 W01" ~ "2019 W52") %>%
#   ggplot(aes(x = date_admitted, y = n)) +
#   geom_line() +
#   geom_vline(xintercept = as.Date(yearweek("2019 W01")), color = "red") +
#   scale_x_yearweek(
#     "Date",
#     breaks = yearweek(paste0(seq(2000, 2020, 1), " W01")), minor_breaks = NULL,
#     labels = as.character(seq(2000, 2020, 1))
#   ) +
#   scale_y_continuous("Case admitted") +
#   ggtitle("Dengue weekly incidence")

# ggsave("weekly_incidence_split_ts.svg", width = 12, height = 7)
```


```{r}
train_weekly_df <- train_weekly_df %>% bind_rows(val_weekly_df)
train_weekly_df %>% tail()

train_weekly_weather_df <- train_weekly_weather_df %>% bind_rows(val_weekly_weather_df)
train_weekly_weather_df %>% tail()
```

# Correlation analysis

## CCF

"The lag k value returned by ccf(x, y) estimates the correlation between x[t+k] and y[t]."

```{r}
incidence_weekly_weather_df %>%
  CCF(n, t2m, lag_max = 52) %>%
  autoplot()

incidence_weekly_weather_df %>%
  mutate(t2m_lagged = lag(t2m, 27)) %>%
  filter(year(date_admitted) < 2019) %>%
  CCF(n, t2m_lagged, lag_max = 52) %>%
  autoplot()

incidence_weekly_weather_df %>%
  CCF(n, precip, lag_max = 52) %>%
  autoplot()

incidence_weekly_weather_df %>%
  mutate(precip_lagged = lag(precip, 13)) %>%
  filter(year(date_admitted) < 2019) %>%
  CCF(n, precip_lagged, lag_max = 52) %>%
  autoplot()
```

```{r}
# train_weekly_weather_df <- incidence_weekly_weather_df %>%
#   mutate(
#     t2m_lagged = lag(t2m, 27),
#     precip_lagged = lag(precip, 10)
#   ) %>%
#   filter_index("2000 W01" ~ "2018 W52")
#
# test_weekly_weather_df <- incidence_weekly_weather_df %>%
#   mutate(
#     t2m_lagged = lag(t2m, 27),
#     precip_lagged = lag(precip, 10)
#   ) %>%
#   filter(year(date_admitted) == 2019) %>%
#   head(4)
```

# Modelling

## Performance checking framework

```{r}
model_perfs <- tibble(
  model = character(),
  RMSE = numeric(),
  CRPS = numeric()
)

source("../utils/performance_checking_framework.R", chdir = TRUE)
```


```{r}
source("../utils/forecast_plotting.R", chdir = TRUE)
source("../utils/chunks_forecasting.R", chdir = TRUE)

forecast_plot_default <- function(fit_df, actual_df, plot_title) {
  fit_df %<>% rename(date_admitted = date, .mean = preds, n = dist)
  ggplot(actual_df) +
    geom_line(aes(x = date_admitted, y = n)) +
    forecast_layer(fit_df) +
    scale_x_yearweek(
      "Week",
      breaks = actual_df$date_admitted[seq(0, 52, 3) + 1],
      labels = as.character(actual_df$date_admitted[seq(0, 52, 3) + 1]) %>% str_extract("W\\d+"),
      minor_breaks = NULL
    ) +
    scale_y_continuous("Incidence") +
    ggtitle(plot_title)
}
```

## Model fitting and forecast framework


```{r}
source("../utils/regression_recur_miso.R", chdir = TRUE)
```

```{r}
unregister_dopar <- function() {
  env <- foreach:::.foreachGlobals
  rm(list = ls(name = env), pos = env)
}
```


## Parallelization setup

```{r}
cl <- makeCluster(9)
invisible(clusterEvalQ(cl, library(tidyverse)))
invisible(clusterEvalQ(cl, library(magrittr)))
invisible(clusterEvalQ(cl, library(tscount)))
invisible(clusterEvalQ(cl, library(tsibble)))
invisible(clusterEvalQ(cl, library(distributional)))
clusterExport(cl, c(
  "%<>%", "incidence_weekly_weather_df", "recur_miso", "test_weekly_df",
  "chunks_forecast_perf", "model_perfs"
))
registerDoParallel(cl)
```

## Poisson

### 1-week lag
```{r}
poi_covar_forecast_df <- recur_miso(
  train_weekly_weather_df, test_weekly_weather_df,
  seq(1, 49, 3),
  model = list(past_obs = 1),
  link = "log", distr = "poisson"
) %>%
  mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

p1 <- forecast_plot_default(
  poi_covar_forecast_df, test_weekly_df,
  "4 week forecast - Poisson regression 1-week lag"
)
p1

ggsave("./svgs/forecast_poisson_l1w.svg", height = 7, width = 10)
```

```{r}
poi_1wl_pre_perf_df <- poi_covar_forecast_df %>%
  select(date, dist, preds, startweek) %>%
  left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
  rename(.mean = preds)

chunks_forecast_res_df <- chunks_forecast_perf(
  poi_1wl_pre_perf_df, "Poisson 1-week lag",
  scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
)

p2 <- metrics_plot(chunks_forecast_res_df, poi_1wl_pre_perf_df$date)
p1 / p2
```

### Auto lagged

```{r}
auto_lagged_df <- foreach(lag = 1:20) %dopar% {
  forecast_df <- recur_miso(
    train_weekly_weather_df, test_weekly_weather_df,
    seq(1, 49, 3),
    model = list(past_obs = lag),
    link = "log", distr = "poisson"
  ) %>%
    mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

  pre_perf_df <- forecast_df %>%
    select(date, dist, preds, startweek) %>%
    left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
    rename(.mean = preds)

  chunks_forecast_res_df <- chunks_forecast_perf(
    pre_perf_df, sprintf("Poisson %d-week lag", lag),
    scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
  )

  tibble(
    model = sprintf("Poisson %d-week lag", lag),
    RMSE = mean(chunks_forecast_res_df$RMSE),
    CRPS = mean(chunks_forecast_res_df$CRPS),
    lag = lag,
    covar = "auto"
  )
}
```

```{r}
lowest_auto_lag <- auto_lagged_df %>%
  list_c() %>%
  filter(CRPS == min(CRPS))

auto_lagged_df %>%
  list_c() %>%
  ggplot(aes(x = lag, y = CRPS)) +
  geom_col() +
  # geom_col(aes(x = lag, y = -RMSE)) +
  geom_point(data = lowest_auto_lag, shape = 4, color = "red", size = 2, stroke = 1.5)

model_perfs %<>%
  bind_rows(lowest_auto_lag)

ggsave("./svgs/forecast_poisson_all_lags.svg", width = 10, height = 7)
```


### Covariables lagged

#### Framework
```{r}
covar_lag_fit <- function(covar_name, lag = 1:20, verbose = TRUE) {
  # browser()
  foreach(lag = lag, .verbose = verbose) %dopar% {
    train_df <- incidence_weekly_weather_df %>%
      mutate(!!covar_name := lag(!!rlang::sym(covar_name), lag)) %>%
      filter_index("2000 W01" ~ "2018 W52")

    test_df <- incidence_weekly_weather_df %>%
      mutate(!!covar_name := lag(!!rlang::sym(covar_name), lag)) %>%
      filter_index("2019 W01" ~ "2019 W52")

    forecast_df <- recur_miso(
      train_df, test_df,
      seq(1, 49, 3),
      model = list(past_obs = 1), xreg_names = c(covar_name),
      link = "log", distr = "poisson"
    ) %>%
      mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

    pre_perf_df <- forecast_df %>%
      select(date, dist, preds, startweek) %>%
      left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
      rename(.mean = preds)

    chunks_forecast_res_df <- chunks_forecast_perf(
      pre_perf_df, sprintf("Poisson %d-week %s lag", lag, covar_name),
      scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
    )

    tibble(
      model = sprintf("Poisson %d-week %s lag", lag, covar_name),
      RMSE = mean(chunks_forecast_res_df$RMSE),
      CRPS = mean(chunks_forecast_res_df$CRPS),
      lag = lag,
      covar = covar_name
    )
  }
}
```

```{r}
best_lag_plot <- function(lag_df) {
  lag_df <- lag_df %>% list_c()
  lowest_lag <- lag_df %>%
    filter(CRPS == min(CRPS))

  print(
    lag_df %>%
      ggplot(aes(x = lag, y = CRPS)) +
      geom_col() +
      geom_point(data = lowest_lag, shape = 4, color = "red", size = 2, stroke = 1.5) +
      ggtitle(sprintf("Poisson regression with %s as covariable, 20-week lags", lowest_lag$covar))
  )

  model_perfs <<- model_perfs %>% bind_rows(lowest_lag)

  lag_df
}
```

#### Fitting

```{r}
covar_names <- incidence_weekly_weather_df %>%
  as_tibble() %>%
  select(-c(date_admitted, n, ssdr, mx2t24)) %>%
  colnames()

all_covars_lagged <- pblapply(covar_names, \(covar) {
  lag_df <- covar_lag_fit(covar, verbose = FALSE)
  best_lag_plot(lag_df)
}) %>% list_c()
```

```{r}
best_lags <- all_covars_lagged %>%
  group_by(covar) %>%
  slice_min(CRPS) %>%
  select(covar, lag) %>%
  deframe() %>%
  as.list()

best_lags
```

### All covariables lagged

```{r}
covar_lagged_df <- incidence_weekly_weather_df %>% mutate(
  across(all_of(covar_names), ~ lag(.x, n = best_lags[[cur_column()]]))
)

train_df <- covar_lagged_df %>%
  filter_index("2000 W01" ~ "2018 W52")

test_df <- covar_lagged_df %>%
  filter_index("2019 W01" ~ "2019 W52")


poi_covar_forecast_df <- recur_miso(
  train_df, test_df,
  seq(1, 49, 3),
  model = list(past_obs = 1), xreg_names = covar_names,
  link = "log", distr = "poisson"
) %>%
  mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

p1 <- forecast_plot_default(
  poi_covar_forecast_df, test_weekly_df,
  "4 week forecast - Poisson regression all covariables lagged"
)
p1

ggsave("./svgs/forecast_poisson_all_covar_lags.svg", width = 10, height = 7)
```

```{r}
poi_covars_pre_perf_df <- poi_covar_forecast_df %>%
  select(date, dist, preds, startweek) %>%
  left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
  rename(.mean = preds)

chunks_forecast_res_df <- chunks_forecast_perf(
  poi_covars_pre_perf_df, "Poisson all covariables lagged",
  scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
)

p2 <- metrics_plot(chunks_forecast_res_df, poi_covars_pre_perf_df$date)
p1 / p2

ggsave("./svgs/forecast_poisson_all_covar_lags_perf.svg", width = 10, height = 7)
```

## Negative Binomial

### 1-week lag

```{r}
nb_covar_forecast_df <- recur_miso(
  train_weekly_weather_df, test_weekly_weather_df,
  seq(1, 49, 3),
  model = list(past_obs = 1),
  link = "log", distr = "nbinom"
) %>%
  mutate(date = yearweek(paste0("2019 W", actualweek)), .before = everything())

p1 <- forecast_plot_default(
  nb_covar_forecast_df, test_weekly_df,
  "4 week forecast - Negative Binomial regression 1-week lag"
)
p1

ggsave("./svgs/forecast_nb_l1w.svg", height = 7, width = 10)
```

```{r}
nb_1wl_pre_perf_df <- nb_covar_forecast_df %>%
  select(date, dist, preds, startweek) %>%
  left_join(test_weekly_df, by = c("date" = "date_admitted")) %>%
  rename(.mean = preds)

chunks_forecast_res_df <- chunks_forecast_perf(
  nb_1wl_pre_perf_df, "NB 1-week lag",
  scoringRules::crps_sample, matrix(parameters(dist)$x[[1]], nrow = n())
)

p2 <- metrics_plot(chunks_forecast_res_df, nb_1wl_pre_perf_df$date)
p1 / p2
```

# Parallelization teardown
```{r}
unregister_dopar()
stopCluster(cl)
```

# Comparison

```{r}
model_perfs
```

```{r}
model_perfs %>% write_csv("glm_models_perf.csv")
```
