---
output: 
  html_document:
    df_print: paged
    toc: yes
    theme: journal
---

**Knitted at: `r Sys.time()`**

# Libraries

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)

library(feasts)
library(tsibble)
library(fable.prophet)
library(fabletools)
library(fable)

library(lubridate)

library(zoo)

library(pbapply)
library(parallel)
```

# Settings
```{r}
theme_set(theme_bw())
```


# Data ingestion

```{r}
source("../time_series_modelling/data_weekly.R")
```


## Incidence data

```{r}
ggplot(incidence_weekly_df, aes(x = date_admitted, y = n)) +
  geom_line() +
  scale_x_yearweek(
    "Date",
    breaks = yearweek(paste0(seq(2000, 2023, 1), " W01")), minor_breaks = NULL,
    labels = as.character(seq(2000, 2023, 1))
  ) +
  scale_y_continuous("Case admitted") +
  ggtitle("Dengue weekly incidence")
```

### Train val test split
```{r}
incidence_weekly_df %>%
  filter_index("2000 W01" ~ "2019 W52") %>%
  ggplot(aes(x = date_admitted, y = n)) +
  geom_line() +
  geom_vline(xintercept = as.Date(yearweek("2018 W01")), color = "red") +
  geom_vline(xintercept = as.Date(yearweek("2019 W01")), color = "red") +
  scale_x_yearweek(
    "Date",
    breaks = yearweek(paste0(seq(2000, 2020, 1), " W01")), minor_breaks = NULL,
    labels = as.character(seq(2000, 2020, 1))
  ) +
  scale_y_continuous("Case admitted") +
  ggtitle("Dengue weekly incidence")
```

## HCMC shape

```{r}
ggplot() +
  geom_sf(data = hcmc_shp_w_buff) +
  geom_sf(data = hcmc_shp)
```

## Weather data


```{r}
raw_weather
```

### Temperature data

```{r}
hcmc_temp_df %>%
  ggplot(aes(x = date, y = t2m)) +
  geom_line() +
  geom_smooth() +
  scale_x_yearweek("Week") +
  scale_y_continuous("2m temperature") +
  ggtitle("Weekly 2m temperature ERA5 reanalysis")

hist(hcmc_temp_df$t2m)
hist(hcmc_temp_df$scaled_t2m)
```

### Precipitation data

```{r}
hcmc_precip_df %>%
  ggplot(aes(x = date, y = precip)) +
  geom_line() +
  geom_smooth() +
  scale_x_yearweek("Week") +
  scale_y_continuous("Total precipitation") +
  ggtitle("Weekly Total precipitation ERA5 reanalysis")

hist(hcmc_precip_df$precip)
hist(hcmc_precip_df$scaled_precip)
```

### Humidity data

```{r}
hcmc_rh_df %>%
  ggplot(aes(x = date, y = rh)) +
  geom_line() +
  geom_smooth() +
  scale_x_yearweek("Week") +
  scale_y_continuous("Total precipitation") +
  ggtitle("Weekly Total precipitation ERA5 reanalysis")

hist(hcmc_rh_df$rh)
hist(hcmc_rh_df$scaled_rh)
```

```{r}
incidence_weekly_weather_df
```

# Performance checking framework

```{r}
model_perfs <- tibble(
  model = character(),
  RMSE = numeric(),
  MAE = numeric()
)

forecast_perf <- function(fit, newdata, model_name, plot = TRUE, res_print = TRUE, res_df = FALSE) {
  forecast <- fit %>%
    predict(newdata = newdata, type = "response") %>%
    as.vector()
  actual <- newdata$n

  if (plot) {
    forecast %>% plot(type = "l")
  }

  rmse <- sqrt(mean((actual - forecast)^2))
  mae <- mean(abs(actual - forecast))

  if (res_print) {
    print(model_name)
    print(sprintf("Test RMSE: %f", rmse))
    print(sprintf("Test MAE: %f", mae))
  }


  if (!res_df) {
    model_perfs <<- model_perfs %>%
      bind_rows(tibble(model = model_name, RMSE = rmse, MAE = mae))
  }

  if (plot) {
    print(newdata %>%
      mutate(forecast = forecast, actual = actual) %>%
      ggplot(aes(x = date_admitted)) +
      geom_line(aes(y = actual)) +
      geom_line(aes(y = forecast), color = "red"))
  }

  if (res_df) {
    return(tibble(model = model_name, RMSE = rmse, MAE = mae))
  }
}
```

# Lag effect

## Hyperparamter tuning

### Function

```{r}
lag_apply <- function(k, covarDf, varcol) {
  lagged_df <- incidence_weekly_df %>%
    left_join(
      covarDf %>% mutate(lagged_value = get(varcol) %>% lag(k)),
      by = c("date_admitted" = "date")
    )

  train_df <- lagged_df %>%
    filter_index("2000 W01" ~ "2017 W52")

  test_df <- lagged_df %>%
    filter_index("2018 W01" ~ "2018 W04")

  fit <- glm(
    n ~ date_admitted + lagged_value,
    family = poisson(), data = train_df
  )

  forecast_perf(
    fit, test_df, sprintf("lag=%d", k),
    plot = FALSE, res_print = FALSE, res_df = TRUE
  )
}

lagged_precip_df <- pbapply::pblapply(
  c(0:52), lag_apply,
  covarDf = hcmc_precip_df, varcol = "precip"
) %>%
  list_c() %>%
  mutate(lag = str_extract(model, "\\d+") %>% as.numeric())

lagged_precip_df %>% ggplot() +
  geom_col(aes(x = lag, y = RMSE))
```


# Alpha

## Accumulation function
```{r}
tsibble_rollsum <- function(df, varcol, datecol, alpha = 10) {
  alpha_df <- zoo(df %>% pull(varcol), df %>% pull(datecol))
  alpha_df %>%
    rollsum(k = alpha) %>%
    timetk::tk_tbl() %>%
    as_tsibble(index = "index")
}
```

## Hyperparameter tuning

### Function
```{r}
alpha_apply <- function(row, covarDf, varcol) {
  alpha <- row["alphas"]
  lag <- row["lags"]

  rollsum_df <-
    incidence_weekly_df %>%
    left_join(
      tsibble_rollsum(covarDf, varcol, "date", alpha = alpha),
      by = c("date_admitted" = "index")
    ) %>%
    mutate(value = lag(value, lag))

  train_df <- rollsum_df %>%
    filter_index("2000 W01" ~ "2017 W52")

  test_df <- rollsum_df %>%
    filter_index("2018 W01" ~ "2018 W04")

  fit <- glm(
    n ~ date_admitted + value,
    family = poisson(), data = train_df
  )

  forecast_perf(
    fit, test_df, sprintf("alpha=%d, lag=%d", alpha, lag),
    plot = FALSE, res_print = FALSE, res_df = TRUE
  )
}

alpha_hyper_grid <- function(covarDf, varcol) {
  # param grid
  lags <- 0:52
  alphas <- 1:52

  param_grid <- expand.grid(lags = lags, alphas = alphas)

  # cluster setup
  cl <- makeCluster(6)
  clusterEvalQ(cl, suppressPackageStartupMessages(library("tidyverse")))
  clusterEvalQ(cl, library("zoo"))
  clusterEvalQ(cl, library("tsibble"))
  clusterExport(cl, ls(globalenv()))

  # hyperparam grid tuning
  apply_res <- pbapply::pbapply(
    param_grid, 1, alpha_apply,
    cl = cl, covarDf = covarDf, varcol = varcol
  )

  # teardown
  stopCluster(cl)

  apply_res %>%
    list_c() %>%
    mutate(
      alpha = str_match(model, ".+=(\\d+).+=.+")[, 2] %>% as.numeric(),
      lag = str_match(model, ".+=.+=(\\d+)")[, 2] %>% as.numeric()
    )
}



alpha_precip_perfs <- alpha_hyper_grid(hcmc_precip_df, "precip")
alpha_temp_perfs <- alpha_hyper_grid(hcmc_temp_df, "t2m")
alpha_rh_perfs <- alpha_hyper_grid(hcmc_rh_df, "rh")

# alpha_precip_perfs %>% write_rds("./grid_perfs/alpha_precip_perfs.rds")
# alpha_temp_perfs %>% write_rds("./grid_perfs/alpha_temp_perfs.rds")
# alpha_rh_perfs %>% write_rds("./grid_perfs/alpha_rh_perfs.rds")
```

### Results

```{r}
best_precip_param <- alpha_precip_perfs %>% filter(RMSE == min(RMSE))
alpha_precip_perfs %>%
  ggplot(aes(x = lag, y = alpha)) +
  geom_tile(aes(fill = RMSE)) +
  geom_point(data = best_precip_param, shape = 4, color = "red") +
  scale_fill_viridis_c() +
  scale_x_continuous("Lagged weeks", breaks = seq(0, 50, 10)) +
  scale_y_continuous("Accumulated weeks (alpha)") +
  ggtitle("Accumulation and lag effect on precipitation, 52-week forecast RMSE")
best_precip_param
```

```{r}
best_t2m_param <- alpha_temp_perfs %>% filter(RMSE == min(RMSE))
alpha_temp_perfs %>%
  ggplot(aes(x = lag, y = alpha)) +
  geom_tile(aes(fill = RMSE)) +
  geom_point(data = best_t2m_param, shape = 4, color = "red") +
  scale_fill_viridis_c() +
  scale_x_continuous("Lagged weeks", breaks = seq(0, 50, 10)) +
  scale_y_continuous("Accumulated weeks (alpha)") +
  ggtitle("Accumulation and lag effect on 2m temperature, 52-week forecast RMSE")
best_t2m_param
```

```{r}
best_rh_param <- alpha_rh_perfs %>% filter(RMSE == min(RMSE))
alpha_rh_perfs %>%
  ggplot(aes(x = lag, y = alpha)) +
  geom_tile(aes(fill = RMSE)) +
  geom_point(data = best_rh_param, shape = 4, color = "red") +
  scale_fill_viridis_c() +
  scale_x_continuous("Lagged weeks", breaks = seq(0, 50, 10)) +
  scale_y_continuous("Accumulated weeks (alpha)") +
  ggtitle("Accumulation and lag effect on relative humidity, 52-week forecast RMSE")
best_rh_param
```


## Testing

### Accumulated + lagged df
```{r}
accum_precip_df <- tsibble_rollsum(hcmc_precip_df, "precip", "date", alpha = 18) %>%
  mutate(value = lag(value, 13)) %>%
  rename(precip = value)

accum_t2m_df <- tsibble_rollsum(hcmc_temp_df, "t2m", "date", alpha = 20) %>%
  mutate(value = lag(value, 50)) %>%
  rename(t2m = value)

accum_rh_df <- tsibble_rollsum(hcmc_rh_df, "rh", "date", alpha = 6) %>%
  mutate(value = lag(value, 37)) %>%
  rename(rh = value)

accum_lagged_df <- accum_precip_df %>%
  left_join(accum_t2m_df) %>%
  left_join(accum_rh_df)
accum_lagged_df
```

```{r}
train_weekly_accum_df <- incidence_weekly_df %>%
  left_join(accum_lagged_df, by = c("date_admitted" = "index")) %>%
  filter_index("2000 W06" ~ "2017 W52")

test_weekly_accum_df <- incidence_weekly_df %>%
  left_join(accum_lagged_df, by = c("date_admitted" = "index")) %>%
  filter_index("2019 W01" ~ "2019 W04")
```

### Testing framework

```{r}
poisson_fit <- function(row) {
  formula <- row$formula
  data <- row$train
  newdata <- row$test
  base_model_name <- row$base_model_name

  fit <- glm(formula = formula, family = poisson(), data = data)

  model_name <- paste0(
    base_model_name, " + ",
    paste(names(fit$coefficients) %>% tail(-2), collapse = " + ")
  )

  forecast_perf(fit, newdata = newdata, model_name = model_name, res_df = TRUE, plot = FALSE, res_print = FALSE)
}

formulas <- c(
  n ~ date_admitted,
  n ~ date_admitted + t2m,
  n ~ date_admitted + precip,
  n ~ date_admitted + rh,
  n ~ date_admitted + t2m + precip,
  n ~ date_admitted + t2m + rh,
  n ~ date_admitted + precip + rh,
  n ~ date_admitted + t2m + precip + rh
)
settings <- list(
  list(train_weekly_weather_df, test_weekly_weather_df %>% head(4), "Poisson"),
  list(train_weekly_accum_df, test_weekly_accum_df, "Poisson accum lagged")
)

model_pars <- expand.grid(formula = formulas, setting = settings) %>%
  as_tibble() %>%
  rowid_to_column() %>%
  unnest(setting) %>%
  mutate(name = rep(c("train", "test", "base_model_name"), n() / 3)) %>%
  pivot_wider(id_cols = c(rowid, formula), values_from = setting) %>%
  mutate(base_model_name = unlist(base_model_name))

cl <- makeCluster(6)
clusterEvalQ(cl, suppressPackageStartupMessages(library("tidyverse")))
clusterExport(cl, c("forecast_perf"))

models_res <- pbapply::pbapply(model_pars, 1, poisson_fit, cl = cl) %>% list_c()

stopCluster(cl)

models_res

# models_res %>% write_csv("./grid_perfs/alpha_poisson_perfs.csv")
```

### Results comparison

```{r}
models_res %>%
  mutate(type = case_when(
    startsWith(model, "Poisson accum lagged") ~ "Poisson accum lagged",
    .default = "Poisson"
  )) %>%
  group_by(type) %>%
  mutate(mean_rmse = mean(RMSE)) %>%
  ggplot() +
  geom_col(aes(y = model, x = RMSE)) +
  geom_vline(aes(xintercept = mean_rmse), color = "red") +
  facet_wrap(~type, ncol = 1, scales = "free_y")
```


# Beta

```{r}
# ref_seq <- hcmc_temp_df %>% head(11)
#
# kernel <- dnorm(seq(-5, 5), sd = 1.1)
#
# convolve(ref_seq$t2m, kernel, type = "filter")
#
#
# beta_df <- zoo(hcmc_temp_df$t2m, hcmc_temp_df$date)
# beta_df %<>%
#   rollapply(width = 11, align = "center", FUN = convolve, y = kernel, type = "filter") %>%
#   timetk::tk_tbl() %>%
#   as_tsibble(index = "index")
# beta_df
#
#
# incidence_weekly_df %>%
#   left_join(hcmc_temp_df, by = c("date_admitted" = "date")) %>%
#   CCF(n, t2m, lag_max = 52) %>%
#   autoplot()
#
# incidence_weekly_df %>%
#   left_join(beta_df, by = c("date_admitted" = "index")) %>%
#   CCF(n, value, lag_max = 52) %>%
#   autoplot()
```

## Delay function

```{r}
tsibble_rollapply <- function(df, varcol, datecol, kernel, width = 11, align = "center") {
  beta_df <- zoo(df %>% pull(varcol), df %>% pull(datecol))
  beta_df %>%
    rollapply(
      width = width, align = "center",
      FUN = convolve, y = kernel, type = "filter"
    ) %>%
    timetk::tk_tbl() %>%
    as_tsibble(index = "index")
}
```

## Hyperparameter tuning

### Function

```{r}
beta_apply <- function(row, covarDf, varcol) {
  beta <- row["betas"]
  lag <- row["lags"]

  gauss_kernel <- dnorm(seq(-5, 5), sd = beta)

  rollapply_df <-
    incidence_weekly_df %>%
    left_join(
      tsibble_rollapply(covarDf, varcol, "date", kernel = gauss_kernel),
      by = c("date_admitted" = "index")
    ) %>%
    mutate(value = lag(value, lag))


  train_df <- rollapply_df %>%
    filter_index("2000 W01" ~ "2017 W52")

  test_df <- rollapply_df %>%
    filter_index("2018 W01" ~ "2018 W04")

  fit <- glm(
    n ~ date_admitted + value,
    family = poisson(), data = train_df
  )

  forecast_perf(
    fit, test_df, sprintf("beta=%d, lag=%d", beta * 10, lag),
    plot = FALSE, res_print = FALSE, res_df = TRUE
  )
}

beta_hyper_grid <- function(covarDf, varcol) {
  # param grid
  lags <- 0:52
  betas <- 1:30

  param_grid <- expand.grid(lags = lags, betas = betas / 10)

  # cluster setup
  cl <- makeCluster(6)
  clusterEvalQ(cl, suppressPackageStartupMessages(library("tidyverse")))
  clusterEvalQ(cl, library("zoo"))
  clusterEvalQ(cl, library("tsibble"))
  clusterExport(cl, ls(globalenv()))

  # hyperparam grid tuning
  apply_res <- pbapply::pbapply(
    param_grid, 1, beta_apply,
    cl = cl, covarDf = covarDf, varcol = varcol
  )

  # teardown
  stopCluster(cl)

  apply_res %>%
    list_c() %>%
    mutate(
      beta = str_match(model, ".+=(\\d+).+=.+")[, 2] %>% as.numeric() / 10,
      lag = str_match(model, ".+=.+=(\\d+)")[, 2] %>% as.numeric(),
    )
}




beta_precip_perfs <- beta_hyper_grid(hcmc_precip_df, "precip")
beta_temp_perfs <- beta_hyper_grid(hcmc_temp_df, "t2m")
beta_rh_perfs <- beta_hyper_grid(hcmc_rh_df, "rh")

# beta_precip_perfs %>% write_rds("./grid_perfs/beta_precip_perfs.rds")
# beta_temp_perfs %>% write_rds("./grid_perfs/beta_temp_perfs.rds")
# beta_rh_perfs %>% write_rds("./grid_perfs/beta_rh_perfs.rds")
```

### Results

```{r}
best_precip_param <- beta_precip_perfs %>% filter(RMSE == min(RMSE))
beta_precip_perfs %>%
  ggplot(aes(x = lag, y = beta)) +
  geom_tile(aes(fill = RMSE)) +
  geom_point(data = best_precip_param, shape = 4, color = "red") +
  scale_fill_viridis_c() +
  scale_x_continuous("Lagged weeks", breaks = seq(0, 50, 10)) +
  scale_y_continuous("Gaussian standard deviation (beta)") +
  ggtitle("Delay and lag effect on precipitation, 52-week forecast RMSE")
best_precip_param
```

```{r}
best_t2m_param <- beta_temp_perfs %>% filter(RMSE == min(RMSE))
beta_temp_perfs %>%
  ggplot(aes(x = lag, y = beta)) +
  geom_tile(aes(fill = RMSE)) +
  geom_point(data = best_t2m_param, shape = 4, color = "red") +
  scale_fill_viridis_c() +
  scale_x_continuous("Lagged weeks", breaks = seq(0, 50, 10)) +
  scale_y_continuous("Gaussian standard deviation (beta)") +
  ggtitle("Delay and lag effect on 2m temperature, 52-week forecast RMSE")
best_t2m_param
```

```{r}
best_rh_param <- beta_rh_perfs %>% filter(RMSE == min(RMSE))
beta_rh_perfs %>%
  ggplot(aes(x = lag, y = beta)) +
  geom_tile(aes(fill = RMSE)) +
  geom_point(data = best_rh_param, shape = 4, color = "red") +
  scale_fill_viridis_c() +
  scale_x_continuous("Lagged weeks", breaks = seq(0, 50, 10)) +
  scale_y_continuous("Gaussian standard deviation (beta)") +
  ggtitle("Delay and lag effect on relative humidity, 52-week forecast RMSE")
best_rh_param
```

## Testing

### Delayed + lagged df
```{r}
delay_precip_df <- tsibble_rollapply(
  hcmc_precip_df, "precip", "date",
  kernel = dnorm(seq(-5, 5), sd = 3)
) %>%
  mutate(value = lag(value, 13)) %>%
  rename(precip = value)

delay_t2m_df <- tsibble_rollapply(
  hcmc_temp_df, "t2m", "date",
  kernel = dnorm(seq(-5, 5), sd = 3)
) %>%
  mutate(value = lag(value, 48)) %>%
  rename(t2m = value)

delay_rh_df <- tsibble_rollapply(
  hcmc_rh_df, "rh", "date",
  kernel = dnorm(seq(-5, 5), sd = 1.8)
) %>%
  mutate(value = lag(value, 36)) %>%
  rename(rh = value)

delay_lagged_df <- delay_precip_df %>%
  left_join(delay_t2m_df) %>%
  left_join(delay_rh_df)
delay_lagged_df
```

```{r}
train_weekly_delay_df <- incidence_weekly_df %>%
  left_join(delay_lagged_df, by = c("date_admitted" = "index")) %>%
  filter_index("2000 W01" ~ "2017 W52")

test_weekly_delay_df <- incidence_weekly_df %>%
  left_join(delay_lagged_df, by = c("date_admitted" = "index")) %>%
  filter_index("2019 W01" ~ "2019 W04")
```

### Testing framework

```{r}
settings <- list(
  list(train_weekly_weather_df, test_weekly_weather_df %>% head(4), "Poisson"),
  list(train_weekly_delay_df, test_weekly_delay_df, "Poisson delayed lagged")
)

model_pars <- expand.grid(formula = formulas, setting = settings) %>%
  as_tibble() %>%
  rowid_to_column() %>%
  unnest(setting) %>%
  mutate(name = rep(c("train", "test", "base_model_name"), n() / 3)) %>%
  pivot_wider(id_cols = c(rowid, formula), values_from = setting) %>%
  mutate(base_model_name = unlist(base_model_name))

cl <- makeCluster(6)
clusterEvalQ(cl, suppressPackageStartupMessages(library("tidyverse")))
clusterExport(cl, c("forecast_perf"))

models_res <- pbapply::pbapply(model_pars, 1, poisson_fit, cl = cl) %>% list_c()

stopCluster(cl)

models_res

# models_res %>% write_csv("./grid_perfs/beta_poisson_perfs.csv")
```

### Results comparison

```{r}
models_res %>%
  mutate(type = case_when(
    startsWith(model, "Poisson delayed lagged") ~ "Poisson delayed lagged",
    .default = "Poisson"
  )) %>%
  group_by(type) %>%
  mutate(mean_rmse = mean(RMSE)) %>%
  ggplot() +
  geom_col(aes(y = model, x = RMSE)) +
  geom_vline(aes(xintercept = mean_rmse), color = "red") +
  facet_wrap(~type, ncol = 1, scales = "free_y")
```


# Alpha + Beta
```{r}
alpha_beta_apply <- function(row, covarDf, varcol) {
  alpha <- row["alphas"]
  beta <- row["betas"]
  # a_lag <- row["alpha_lags"]
  # b_lag <- row["beta_lags"]
  lag <- row["lags"]

  gauss_kernel <- dnorm(seq(-5, 5), sd = beta)

  roll_df <- incidence_weekly_df %>%
    left_join(
      tsibble_rollsum(covarDf, varcol, "date", alpha = alpha) %>%
        rename(accum_val = value),
      by = c("date_admitted" = "index")
    ) %>%
    left_join(
      tsibble_rollapply(covarDf, varcol, "date", kernel = gauss_kernel) %>%
        rename(delay_val = value),
      by = c("date_admitted" = "index")
    ) %>%
    mutate(
      accum_val = lag(accum_val, lag),
      delay_val = lag(delay_val, lag),
    )

  train_df <- roll_df %>%
    filter_index("2000 W01" ~ "2017 W52")

  test_df <- roll_df %>%
    filter_index("2018 W01" ~ "2018 W52")

  fit <- glm(
    n ~ date_admitted + accum_val + delay_val,
    family = poisson(), data = train_df
  )

  forecast_perf(
    # fit, test_df, sprintf("alpha=%d, a_lag=%d, beta=%d, b_lag=%d", alpha, a_lag, beta * 10, b_lag),
    fit, test_df, sprintf("alpha=%d, beta=%d, b_lag=%d", alpha, beta * 10, lag),
    plot = FALSE, res_print = FALSE, res_df = TRUE
  )
}

alpha_beta_hyper_grid <- function(covarDf, varcol) {
  # param grid
  alphas <- 1:52
  betas <- 1:30
  # alpha_lags <- 0:52
  # beta_lags <- 0:52
  lags <- 0:52

  param_grid <- expand.grid(
    alphas = alphas, betas = betas, lags = lags # , alpha_lags = alpha_lags, beta_lags = beta_lags
  )

  # cluster setup
  cl <- makeCluster(6)
  clusterEvalQ(cl, suppressPackageStartupMessages(library("tidyverse")))
  clusterEvalQ(cl, library("zoo"))
  clusterEvalQ(cl, library("tsibble"))
  clusterExport(cl, ls(globalenv()))

  # hyperparam grid tuning
  apply_res <- pbapply::pbapply(
    param_grid, 1, alpha_beta_apply,
    cl = cl, covarDf = covarDf, varcol = varcol
  )

  # teardown
  stopCluster(cl)

  apply_res %>%
    list_c()
}

alpha_beta_precip_perfs <- alpha_beta_hyper_grid(hcmc_precip_df, "precip")

#########################################################

# alpha_beta_precip_perfs <- alpha_hyper_grid(hcmc_precip_df, "precip")
# alpha_temp_perfs <- alpha_hyper_grid(hcmc_temp_df, "t2m")
# alpha_rh_perfs <- alpha_hyper_grid(hcmc_rh_df, "rh")
```
